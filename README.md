# Exploring pre-trained models - GPT-2, BERT, ChatGPTðŸ¤–

## GPT-2:

- Demonstrations on text generation using GPT-2 model.

## BERT:

- Utilization of BERT (Bidirectional Encoder Representations from Transformers) for natural language processing tasks like text classification, named entity recognition, and sentiment analysis.
- Loading pre-trained BERT model and tokenizer, followed by an example of sentiment analysis.

## Sentiment Analysis:

- Creation of a dataset for sentiment analysis containing sample sentences and corresponding sentiments.
- Implementation of sentiment prediction function using BERT and application on the dataset.

<img src="https://github.com/CatelloTheDataProjectManager/Exploring-pre-trained-models/blob/main/Sentiment_Analysis.png" alt="Sales Report Image" width="800">

## ChatGPT:

- Integration of OpenAI's ChatGPT model for generating conversational responses.
- Examples of generating responses to given prompts using ChatGPT.
- Utilization of ChatGPT for answering specific questions like crafting effective prompts and commenting on sentiment analysis results.

[Notebook Jupyeter: Exploring pre-trained models](https://github.com/CatelloTheDataProjectManager/Exploring-pre-trained-models/blob/main/Exploring%20pre-trained%20models.ipynb)

Feel free to explore the code and documentation. Your feedback and contributions are highly valued! ðŸš€
